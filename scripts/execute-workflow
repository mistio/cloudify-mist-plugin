#!/usr/bin/env python

"""Execute a Cloudify Workflow on a Mist.io Stack.

This executable takes care of fetching the Stack's Template, unpacking it, if
it is a tarball/zip file, and actually executing the instructed orchestration
workflow using the MistClient and Cloudify CLI.

"""

import os
import sys
import json
import glob
import copy
import random
import shutil
import urllib
import tarfile
import zipfile
import logging
import requests
import subprocess

from mistclient import MistClient


requests.packages.urllib3.disable_warnings(
    requests.packages.urllib3.exceptions.InsecureRequestWarning
)

log = logging.getLogger(__name__)


def main():
    """Fetch and run executable script or ansible playbook"""

    args = parse_args()

    loglvl = logging.DEBUG if args.verbose else logging.INFO
    logfmt = "[%(asctime)-15s][%(levelname)s] - %(message)s"
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter(logfmt))
    handler.setLevel(loglvl)  # Overridden by configuration
    log.addHandler(handler)
    log.setLevel(loglvl)

    randid = '%x' % random.randrange(2 ** 128)
    mksep = lambda part: '-----part-%s-%s-----' % (part, randid)
    kwargs = {}
    cmdret = []
    stack = {}
    node_instances = []
    outputs = {}

    try:
        client = MistClient(api_token=args.apitoken,
                            mist_uri=args.uri)
        stack = client.show_stack(args.stack_id)
        inputs = stack["inputs"]
        template_id = stack["template"]
        template = client.show_template(template_id)
        template_inputs = [ i['name'] for i in template['inputs'] ]

        if 'mist_uri' in inputs.get('install', ''):
            inputs['install']['mist_uri'] = args.uri
        if 'mist_token' in inputs.get('install', ''):
            inputs['install']['mist_token'] = args.apitoken

        # Storing the job ID corresponding to the particular Stack in order to
        # create nested logs during the execution of Cloudify workflows. The
        # logs generated by each workflow will use this job ID as their origin
        # TODO: Pass as ENV variables.
        with open('/tmp/cloudify-mist-plugin-job', 'w') as jf:
            jf.write(str(stack['job_id']))
        # Store the Stack's name
        with open('/tmp/cloudify-mist-plugin-stack', 'w') as sf:
            sf.write(str(stack['name']))

        location_type = template["location_type"]
        if location_type == "inline":
            f = open("template.yaml")
            f.write(template["template"])
            f.close()
            entrypoint = "template.yaml"
        elif location_type == "github":
            repo = template["template"].replace("https://github.com/", "")
            repo = repo.split("tree/")
            if len(repo) > 1:
                branch = repo[1]
            else:
                branch = "master"
            repo = repo[0]
            if repo.endswith("/"):
                repo = repo.rstrip("/")
            sha_path = 'https://api.github.com/repos/%s/commits' % repo
            headers = {}
            resp = requests.get(sha_path, headers=headers)
            resp = resp.json()
            # latest_sha = resp[0]["sha"]
            tarball_path = 'https://api.github.com/repos/%s/tarball/%s' % (repo, branch)
            resp = requests.get(tarball_path, headers=headers,
                                allow_redirects=False)
            if resp.ok and resp.is_redirect and 'location' in resp.headers:
                path = resp.headers['location']
            else:
                print mksep('end')
                print mksep('summary')
                exc = Exception("Couldn't download git project")
                log.critical(exc)
                print mksep('end')
                return -1
            path = download(path)
            try:
                unpack(path, '/tmp/templates/')
            except:
                pass
            else:
                path = find_path('/tmp/templates', template["entrypoint"])

        folder = find_folder('/tmp/templates')
        os.chdir(folder)
        f = open("inputs.json", "wb")
        f.write(json.dumps(inputs['install']))
        f.close()
        cmd = 'cfy local init -p {0} -i inputs.json'.format(path)
        local_instances = os.path.join(folder,
                                       "local-storage/local/node-instances")
        cmdret.append(shellcmd(cmd, break_on_error=False))
        if stack["node_instances"]:
            shutil.rmtree('local-storage/local/node-instances')
            os.mkdir("local-storage/local/node-instances")
            for instance in stack["node_instances"]:
                data = open(os.path.join(local_instances, instance["id"]), "w")
                data.write(json.dumps(instance))
                data.close()
        print mksep('end')
        print mksep('execute')
        cmd = "cfy local execute -w {0}".format(args.workflow)
        if args.workflow != 'install' and inputs.get(args.workflow):
            f = open("workflow_inputs.json", "wb")
            f.write(json.dumps(inputs[args.workflow]))
            f.close()
            cmd = cmd + " -p workflow_inputs.json"
        cmdret.append(shellcmd(cmd, break_on_error=False))
        exit_code = cmdret[-1][0]
        for instance in os.listdir(local_instances):
#            print mksep('end')
#            print mksep('cloudifyinstance')
            i = open(os.path.join(local_instances, instance)).read()
#            print i
            node_instances.append(json.loads(i))

        print mksep('end')
        print mksep('summary')
        log.info('Wrapper script execution finished. User script exited with '
                 'rc %s' % exit_code)
        error = False
        if not exit_code:
            cmd = 'cfy local outputs'
            outputs = shellcmd(cmd, break_on_error=False)
            cmdret.append(outputs)
            outputs = json.loads(outputs[1])
    except Exception as exc:
        print mksep('end')
        print mksep('summary')
        log.critical(exc)
        exit_code = -1
        error = str(exc)

    client.end_job(stack['job_id'],
                   exit_code=exit_code,
                   cmdout=cmdret,
                   error=error or exit_code or False,
                   node_instances=node_instances,
                   outputs=outputs)
    return exit_code


def shellcmd(cmd, env={}, su=False, break_on_error=True, _out=''):
    """Run a command using the shell"""
    environ = os.environ.copy()
    environ.update(env)
    log.debug("Running command '%s'.", cmd)
    p = subprocess.Popen(cmd.split(' '), env=environ, stdout=subprocess.PIPE,
                         stderr=subprocess.STDOUT, universal_newlines=True)

    def _stream(proc):
        for _line in iter(proc.stdout.readline, ''):
            yield _line

    for next_line in _stream(p):
        _out += next_line
        sys.stdout.write(next_line)
        sys.stdout.flush()

    out, err = p.communicate()  # `out` is not returned by communicate()
    out = _out
    return_code = p.returncode

    if return_code:
        err = "Command '%s' exited with return code %d." % (cmd, return_code)
        if break_on_error:
            raise Exception(err)
        else:
            log.error(err)
    return (return_code, out, err)


def download(url, path=None):
    """Download a file over HTTP"""
    log.debug("Downloading %s.", url)
    name, headers = urllib.urlretrieve(url, path)
    log.debug("Downloaded to %s.", name)
    return name


def unpack(path, dirname='.'):
    """Unpack a tar or zip archive"""
    if tarfile.is_tarfile(path):
        log.debug("Unpacking '%s' tarball in directory '%s'.", path, dirname)
        tfile = tarfile.open(path)
        if hasattr(tfile, 'extractall'):
            tfile.extractall(dirname)
        else:
            for tarinfo in tfile:
                if tarinfo.isdir():
                    tarinfo = copy.copy(tarinfo)
                    tarinfo.mode = 0700
                tfile.extract(tarinfo, dirname)
    elif zipfile.is_zipfile(path):
        log.debug("Unpacking '%s' zip archive in directory '%s'.",
                  path, dirname)
        zfile = zipfile.ZipFile(path)
        if hasattr(zfile, 'extractall'):
            zfile.extractall(dirname)
        else:
            for member_path in zfile.namelist():
                dirname, filename = os.path.split(member_path)
                if dirname and not os.path.exists(dirname):
                    os.makedirs(dirname)
                zfile.extract(member_path, dirname)
    else:
        raise Exception("File '%s' is not a valid tar or zip archive." % path)


def find_folder(dirname='.'):
    """Find absolute path of script"""
    dirname = os.path.abspath(dirname)
    if not os.path.isdir(dirname):
        log.warning("Directory '%s' doesn't exist, will search in '%s'.",
                    dirname, os.getcwd())
        dirname = os.getcwd()
    ldir = os.listdir(dirname)
    if not ldir:
        raise Exception("Directory '%s' is empty." % dirname)
    if len(ldir) == 1:
        path = os.path.join(dirname, ldir[0])
        if os.path.isdir(path):
            dirname = path
            return path
    else:
        raise Exception("No folder found")


def find_path(dirname='.', filename=''):
    """Find absolute path of script"""
    dirname = os.path.abspath(dirname)
    if not os.path.isdir(dirname):
        log.warning("Directory '%s' doesn't exist, will search in '%s'.",
                    dirname, os.getcwd())
        dirname = os.getcwd()
    while True:
        log.debug("Searching for entrypoint '%s' in directory '%s'.",
                  filename or 'main.*', dirname)
        ldir = os.listdir(dirname)
        if not ldir:
            raise Exception("Directory '%s' is empty." % dirname)
        if len(ldir) == 1:
            path = os.path.join(dirname, ldir[0])
            if os.path.isdir(path):
                dirname = path
                continue
            break
        if filename:
            path = os.path.join(dirname, filename)
            if os.path.isfile(path):
                break
        paths = glob.glob(os.path.join(dirname, 'main.*'))
        if not paths:
            raise Exception("No files match 'main.*' in '%s'." % dirname)
        if len(paths) > 1:
            log.warning("Multiple files match 'main.*' in '%s'.", dirname)
        path = paths[0]
        break
    log.info("Found entrypoint '%s'.", path)
    return path


def parse_args():
    """Parse command line arguments"""
    try:
        import argparse
        parser = argparse.ArgumentParser(
            description="Fetch and run executable script or ansible playbook.",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        )
        parser.add_argument('stack_id',
                            help="The id of the stack")
        parser.add_argument('-w', '--workflow', type=str, default='install',
                            help="Run workflow on orchestration template.")
        parser.add_argument('-d', '--workdata', type=str,
                            help="String of params to pass to workflow.")
        parser.add_argument('-u', '--uri', type=str, default='https://mist.io',
                            help="Mist uri instance to connect to.")
        parser.add_argument('-t', '--apitoken', type=str,
                            help="Api token to use for authentication.")
        parser.add_argument('-v', '--verbose', action='store_true',
                            help="Show debug logs.")
        args = parser.parse_args()
    except ImportError:
        # Python 2.6 does not have argparse
        import optparse
        parser = optparse.OptionParser("usage: %prog [options] script")
        parser.add_option('-w', '--workflow', type=str,
                          help="Run workflow on orchestration template.")
        parser.add_option('-d', '--workdata', type=str,
                          help="String of params to pass to workflow.")

        parser.add_option('-u', '--uri', type=str, default='https://mist.io',
                          help="Mist uri instance to connect to.")
        parser.add_option('-v', '--verbose', action='store_true',
                          help="Show debug logs.")
        parser.add_option('-t', '--apitoken', type=str,
                          help="Api token to use for authentication.")
        args, list_args = parser.parse_args()
        args.stack_id = list_args[0]
    return args


if __name__ == "__main__":
    sys.exit(main())
